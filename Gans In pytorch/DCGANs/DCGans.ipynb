{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gans architecture\n",
    "Paper:[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "![imge](screenshot_7.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this is the Generator architecture\n",
    "- the discriminator architecture is the opposite of the generator architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of the network\n",
    "- Replace all pooling layers with strided convolutions.\n",
    "- Remove all fully connected layers.\n",
    "- Use transposed convolutions for upsampling.\n",
    "- Use Batch Normalization after every layer except after the output layer of the generator and the input layer of the discriminator.\n",
    "- Use ReLU non-linearity for each layer in the generator except for output layer  use tanh.\n",
    "- Use Leaky-ReLU non-linearity for each layer of the disciminator excpet for output layer use sigmoid."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Hyperparameters are chosen as given in the paper.\n",
    "\n",
    "- mini-batch size: 128\n",
    "- learning rate: 0.0002\n",
    "- momentum term beta1: 0.5\n",
    "- slope of leak of LeakyReLU: 0.2\n",
    "- For the optimizer Adam (with beta2 = 0.999) has been used instead of SGD as described in the paper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channel_num, filters_num) -> None:  # * channel_num: 3, filters_num is the number of filters in the first layer\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # * Input: (N, channel_num, 64, 64)\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channel_num,\n",
    "                filters_num,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # * Input: (N, filters_num, 32, 32)\n",
    "            self._block(filters_num, filters_num * 2, 4, 2, 1),\n",
    "            # * Input: (N, filters_num*2, 16, 16)\n",
    "            self._block(filters_num*2, filters_num * 4, 4, 2, 1),\n",
    "            # * Input: (N, filters_num*8, 8, 8)\n",
    "            self._block(filters_num*4, filters_num * 8, 4, 2, 1),\n",
    "            # * Input: (N, filters_num*8, 4, 4)\n",
    "            nn.Conv2d(filters_num * 8, 1, kernel_size=4, stride=2, padding=0, bias=False),\n",
    "            # * Output: (N, 1, 1, 1)\n",
    "            #nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=False,  # * No bias in batch norm\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(3, 64) #* 3 channels, starting with 64 filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _output_shape_cal(input_shape, kernel_size, stride, padding):\n",
    "    return (input_shape - kernel_size + 2 * padding) / stride + 1\n",
    "\n",
    "_output_shape_cal(64, 4, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchinfo import summary\n",
    "\n",
    "#summary(disc, (1, 3, 64, 64), device=\"cuda\", verbose=0)\n",
    "# 1, 3 , 64, 64 -> 1, 64, 32, 32 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim , channel_num, filters_num) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            #* Input: (N, z_dim, 1, 1)\n",
    "            self._block(z_dim, filters_num*16, 4, 1, 0),\n",
    "            \n",
    "            #* Input: (N, filters_num*16, 4, 4)\n",
    "            self._block(filters_num*16, filters_num*8, 4, 2, 1), \n",
    "            \n",
    "            #* Input: (N, filters_num*8, 8, 8)\n",
    "            self._block(filters_num*8, filters_num*4, 4, 2, 1),\n",
    "            \n",
    "            #* Input: (N, filters_num*4, 16, 16)\n",
    "            self._block(filters_num*4, filters_num*2, 4, 2, 1),\n",
    "            \n",
    "            \n",
    "            #self._block(filters_num*2, filters_num, 4, 2, 1),\n",
    "            \n",
    "            #* Input: (N, filters_num*2, 32, 32)\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels = filters_num*2,\n",
    "                out_channels= channel_num,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1),\n",
    "            #* Output: (N, channel_num, 64, 64)\n",
    "            nn.Tanh(), #* [-1, 1]\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=False,  # * No bias in batch norm\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen = Generator(100, 3, 64)\n",
    "#gen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m , (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            #* Initializing weights\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02) #* Normal distribution with mean 0 and std 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 1, 1])\n",
      "torch.Size([8, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "N, in_channels, H, W = 8, 3, 64, 64\n",
    "z_dim = 100\n",
    "x = torch.randn((N, in_channels, H, W))\n",
    "disc = Discriminator(in_channels, 8)\n",
    "initializing_weights(disc)\n",
    "print(disc(x).shape) #*-> get down to 1, 1, 1\n",
    "gen = Generator(z_dim, in_channels, 8)\n",
    "z = torch.randn((N, z_dim, 1, 1))\n",
    "initializing_weights(gen)\n",
    "print(gen(z).shape) #* -> upsacle to 1, 3, 64, 64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.model import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = 'cpu'\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 32\n",
    "IMAG_SIZE = 64\n",
    "CHANNELS_IMG = 1 \n",
    "Z_DIM = 100\n",
    "NUM_EPOCH = 5\n",
    "\n",
    "FEATURES_DISC = 64 #* NUMBER OF FILETER IN DISCRIMINATOR\n",
    "FEATURES_GEN = 64 #* NUMBER OF FILETER IN GENERATOR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([\n",
    "    transforms.Resize(IMAG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    ")]) #* mean and std = [0.5] [0.5] for each channel\n",
    "    \n",
    "                                    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =datasets.MNIST(\n",
    "    root='data/',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transformation,\n",
    "    target_transform=None,\n",
    ")\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset= dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cearing Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(\n",
    "    z_dim= Z_DIM,\n",
    "    channel_num= CHANNELS_IMG,\n",
    "    filters_num= FEATURES_GEN,\n",
    ").to(device)\n",
    "\n",
    "disc = Discriminator(\n",
    "    channel_num= CHANNELS_IMG,\n",
    "    filters_num=FEATURES_DISC\n",
    ").to(device)\n",
    "\n",
    "\n",
    "#* initialize weights with normal distribution of mean 0 and std 0.02\n",
    "initializing_weights(gen)\n",
    "initializing_weights(disc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOSS and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_gen = optim.Adam(\n",
    "    params=gen.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(0.5, 0.999)  # * beta1 and beta2 ? default = (0.9, 0.999)\n",
    "    # * beta1: exponential decay rate for the first moment estimates\n",
    "    # * beta2: exponential decay rate for the second moment estimates\n",
    "    # * beta1 and beta2 are used to calculate the first and second moment estimates\n",
    "    #*  coefficients used for computing running averages of gradient and its square\n",
    ")\n",
    "\n",
    "opt_disc = optim.Adam(params=disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss() \n",
    "#loss_no_logits = nn.BCELoss()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fews more steps + tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(32, Z_DIM,1,1)\n",
    "fixed_noise.shape\n",
    "\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(F'logs/fake')\n",
    "step = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "real, _ = next(iter(loader))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def get_Disc_loss(gen, disc, real, batch_size, z_dim, criterion, device):\n",
    "    real = real.to(device)\n",
    "    noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n",
    "    gen_images = gen(noise)\n",
    "\n",
    "    disc_fake = disc(gen_images).detach().reshape(-1)\n",
    "    disc_real = disc(real).reshape(-1)\n",
    "\n",
    "    Disc_fake_loss = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "    Disc_real_loss = criterion(disc_real, torch.ones_like(disc_real))\n",
    "    Disc_loss = (Disc_fake_loss + Disc_real_loss) / 2\n",
    "    return Disc_loss\n",
    "\n",
    "# opt_disc.zero_grad()\n",
    "# Disc_loss = get_Disc_loss(gen, disc , real, BATCH_SIZE, Z_DIM, criterion, opt_disc , device)\n",
    "# Disc_loss.backward(retain_graph=True)\n",
    "# opt_disc.step()\n",
    "\n",
    "# Disc_loss.item()\n",
    "# get_Disc_loss(gen, disc , real, BATCH_SIZE, Z_DIM, criterion, opt_disc , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, batch_size, z_dim, criterion, device):\n",
    "    noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n",
    "    generated_img = gen(noise).detach()\n",
    "    disc_gen = disc(generated_img)\n",
    "    Gen_loss = criterion(disc_gen, torch.ones_like(disc_gen))\n",
    "    return Gen_loss\n",
    "\n",
    "# opt_gen.zero_grad()\n",
    "# Gen_loss = get_gen_loss(gen, disc, BATCH_SIZE, Z_DIM, criterion)\n",
    "# Gen_loss.backward()\n",
    "# opt_gen.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0e9ca850bb4270ad8ce8424ea5d7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([3.0], [3.0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "epochs = 1\n",
    "# BATCH_SIZE = 16\n",
    "gen.train()\n",
    "disc.train()\n",
    "gen_loss_hist = []\n",
    "disc_loss_hist = []\n",
    "for _ in range(epochs):\n",
    "    total_disc_loss = 0\n",
    "    total_gen_loss = 0\n",
    "    for batch_idx , (real, _) in enumerate(tqdm(loader)):\n",
    "        # real, _ = next(iter(loader))\n",
    "        real = real.to(device)\n",
    "        opt_disc.zero_grad()\n",
    "        Disc_loss = get_Disc_loss(disc=disc,\n",
    "                                gen=gen,\n",
    "                                real=real,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                z_dim=Z_DIM,\n",
    "                                criterion=criterion,\n",
    "                                device='cuda'\n",
    "                                )\n",
    "        Disc_loss.backward()\n",
    "        opt_disc.step()\n",
    "        \n",
    "        total_disc_loss += Disc_loss.item()\n",
    "        \n",
    "        opt_gen.zero_grad()\n",
    "        Gen_loss = get_gen_loss(\n",
    "            disc=disc,\n",
    "            gen=gen,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            z_dim=Z_DIM,\n",
    "            criterion=criterion,\n",
    "            device=device\n",
    "        )\n",
    "        opt_gen.step()\n",
    "        total_gen_loss += Gen_loss.item()\n",
    "        \n",
    "    disc_loss_hist.append(total_disc_loss//len(loader))\n",
    "    gen_loss_hist.append(total_disc_loss//len(loader))\n",
    "\n",
    "disc_loss_hist, gen_loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d9c3c500b8bab2cdd86682acf135365680fb2fcb10592a31bb294351b9c146c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
